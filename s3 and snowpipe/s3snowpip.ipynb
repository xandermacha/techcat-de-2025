{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a604d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9278b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3',\n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "    region_name=os.getenv('AWS_REGION')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e395b3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capstone-techcatalyst-conformed\n",
      "capstone-techcatalyst-raw\n",
      "capstone-techcatalyst-transformed\n",
      "techcatalyst-public\n",
      "techcatalyst-raw\n",
      "techcatalyst-transformed\n"
     ]
    }
   ],
   "source": [
    "buckets = s3_client.list_buckets()\n",
    "for bucket in buckets['Buckets']:\n",
    "    if 'techcatalyst' in bucket['Name']:\n",
    "        print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56c80b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLAKE/test.csv\n",
      "BLAKE/test2.csv\n",
      "BLAKE/test3.csv\n",
      "BLAKE/test4.csv\n",
      "BLAKE/test4.parquet/3eb3c7a40840497db7f67c4b60cb78d0.snappy.parquet\n",
      "BLAKE/test_export.parquet\n",
      "BLAKE/upload_file_method_GOOG.csv\n",
      "BLAKE/upload_fileobj_method.txt\n",
      "BLAKE_wr/9288e6c1eed4476d98eade7875cbf9c0.snappy.parquet\n",
      "BLAKE_wr/uploads/wr_newfile.csv\n",
      "Ben/Million_Songs/\n",
      "Ben/bingchilling.txt\n",
      "Ben/gooooog.csv\n",
      "Ben/parquetGoogleStock/a0eeb97dbd854a5c9cc6e89512faee73.snappy.parquet\n",
      "Ben/test.csv\n",
      "Ben/uploads/Google_upload_test\n",
      "EMMA/emna_goog.csv\n",
      "EMMA/emna_goog.txt\n",
      "EMMA/test_export.parquet\n",
      "MELISSA/test.csv\n",
      "MELISSA/uploads/GOOG.csv\n",
      "MELISSA/uploads/fileobj.txt\n",
      "MELISSA/uploads/new_file.csv\n",
      "MillionSongSubset/\n",
      "MillionSongSubset/log-data/2018-11-01-events.json\n",
      "MillionSongSubset/log-data/2018-11-02-events.json\n",
      "MillionSongSubset/log-data/2018-11-03-events.json\n",
      "MillionSongSubset/log-data/2018-11-04-events.json\n",
      "MillionSongSubset/log-data/2018-11-05-events.json\n",
      "MillionSongSubset/log-data/2018-11-06-events.json\n",
      "MillionSongSubset/log-data/2018-11-07-events.json\n",
      "MillionSongSubset/log-data/2018-11-08-events.json\n",
      "MillionSongSubset/log-data/2018-11-09-events.json\n",
      "MillionSongSubset/log-data/2018-11-10-events.json\n",
      "MillionSongSubset/log-data/2018-11-11-events.json\n",
      "MillionSongSubset/log-data/2018-11-12-events.json\n",
      "MillionSongSubset/log-data/2018-11-13-events.json\n",
      "MillionSongSubset/log-data/2018-11-14-events.json\n",
      "MillionSongSubset/log-data/2018-11-15-events.json\n",
      "MillionSongSubset/log-data/2018-11-16-events.json\n",
      "MillionSongSubset/log-data/2018-11-17-events.json\n",
      "MillionSongSubset/log-data/2018-11-18-events.json\n",
      "MillionSongSubset/log-data/2018-11-19-events.json\n",
      "MillionSongSubset/log-data/2018-11-20-events.json\n",
      "MillionSongSubset/log-data/2018-11-21-events.json\n",
      "MillionSongSubset/log-data/2018-11-22-events.json\n",
      "MillionSongSubset/log-data/2018-11-23-events.json\n",
      "MillionSongSubset/log-data/2018-11-24-events.json\n",
      "MillionSongSubset/log-data/2018-11-25-events.json\n",
      "MillionSongSubset/log-data/2018-11-26-events.json\n",
      "MillionSongSubset/log-data/2018-11-27-events.json\n",
      "MillionSongSubset/log-data/2018-11-28-events.json\n",
      "MillionSongSubset/log-data/2018-11-29-events.json\n",
      "MillionSongSubset/log-data/2018-11-30-events.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAAAW128F429D538.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAABD128F429CF47.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAADZ128F9348C2E.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAAEF128F4273421.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAAFD128F92F423A.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAAMO128F1481E7F.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAAMQ128F1460CD3.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAAPK128E0786D96.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAARJ128F9320760.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAAVG12903CFA543.json\n",
      "MillionSongSubset/song_data/A/A/A/TRAAAVO128F93133D4.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABCL128F4286650.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABDL12903CAABBA.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABJL12903CDCF1A.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABJV128F1460C49.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABLR128F423B7E3.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABNV128F425CEE1.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABRB128F9306DD5.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABVM128F92CA9DC.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABXG128F9318EBD.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABYN12903CFD305.json\n",
      "MillionSongSubset/song_data/A/A/B/TRAABYW128F4244559.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACCG128F92E8A55.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACER128F4290F96.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACFV128F935E50B.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACHN128F1489601.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACIW12903CC0F6D.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACLV128F427E123.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACNS128F14A2DF5.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACOW128F933E35F.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACPE128F421C1B9.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACQT128F9331780.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACSL128F93462F4.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACTB12903CAAF15.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACVS128E078BE39.json\n",
      "MillionSongSubset/song_data/A/A/C/TRAACZK128F4243829.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABACN128F425B784.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABAFJ128F42AF24E.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABAFP128F931E9A1.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABAIO128F42938F9.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABATO128F42627E9.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABAVQ12903CBF7E0.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABAWW128F4250A31.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABAXL128F424FC50.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABAXR128F426515F.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABAXV128F92F6AE3.json\n",
      "MillionSongSubset/song_data/A/B/A/TRABAZH128F930419A.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBAM128F429D223.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBBV128F42967D7.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBJE12903CDB442.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBKX128F4285205.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBLU128F93349CF.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBNP128F932546F.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBOP128F931B50D.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBOR128F4286200.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBTA128F933D304.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBVJ128F92F7EAA.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBXU128F92FEF48.json\n",
      "MillionSongSubset/song_data/A/B/B/TRABBZN12903CD9297.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCAJ12903CDFCC2.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCEC128F426456E.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCEI128F424C983.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCFL128F149BB0D.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCIX128F4265903.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCKL128F423A778.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCPZ128F4275C32.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCRU128F423F449.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCTK128F934B224.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCUQ128E0783E2B.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCXB128F4286BD3.json\n",
      "MillionSongSubset/song_data/A/B/C/TRABCYE128F934CE1D.json\n",
      "YOURNAME/test_export.parquet\n",
      "aamnah/172a5341ccd94b8f95dd05dc3410e9d0_000000_000000.snappy.parquet\n",
      "aamnah/172a5341ccd94b8f95dd05dc3410e9d0_000001_000000.snappy.parquet\n",
      "aamnah/172a5341ccd94b8f95dd05dc3410e9d0_000002_000000.snappy.parquet\n",
      "aamnah/172a5341ccd94b8f95dd05dc3410e9d0_000003_000000.snappy.parquet\n",
      "aamnah/uploads/GOOG_NEW.csv\n",
      "accidents/\n",
      "accidents/accidents_2017_to_2023_english.csv\n",
      "alexia/957133637c684b09a94cc753e0c594a2_000000_000000.snappy.parquet\n",
      "alexia/957133637c684b09a94cc753e0c594a2_000001_000000.snappy.parquet\n",
      "alexia/957133637c684b09a94cc753e0c594a2_000002_000000.snappy.parquet\n",
      "alexia/957133637c684b09a94cc753e0c594a2_000003_000000.snappy.parquet\n",
      "alexia/secret_formula.txt\n",
      "alexia/upload_GOOG.csv\n",
      "emma/3a1b7394faa84991a5e7700c963af73f_000000_000000.snappy.parquet\n",
      "emma/3a1b7394faa84991a5e7700c963af73f_000001_000000.snappy.parquet\n",
      "emma/3a1b7394faa84991a5e7700c963af73f_000002_000000.snappy.parquet\n",
      "emma/3a1b7394faa84991a5e7700c963af73f_000003_000000.snappy.parquet\n",
      "emma/uploads/wr_emma_stock\n",
      "fabiola/a3a03886216d40279ccfca68cc237524.snappy.parquet\n",
      "fabiola/test.csv\n",
      "fabiola/uploads/wr_GOOG.csv\n",
      "jaden/6e08eee074434aa7abda59ab22bc3ea7.snappy.parquet\n",
      "jaden/test.csv\n",
      "jaden/uploads/new_file.csv\n",
      "michael/e798e42882254cf5a9e99351bd7626d6.snappy.parquet\n",
      "miraj/DOWNLOADEDGOOGLEDATA.csv\n",
      "miraj/aa649f748f1a444e98540e3bbe3135d1.snappy.parquet\n",
      "miraj_jara/uploads/google_stock_data\n",
      "shaswat/e4e70d26665c4d07af4bdaab85f8975e.snappy.parquet\n",
      "shaswat/test.csv\n",
      "shaswat/uploads/new_file.csv\n",
      "stage/\n",
      "stage/yellow_tripdata.csv\n",
      "stage/yellow_tripdata.json\n",
      "stage/yellow_tripdata.parquet\n",
      "stocks/\n",
      "stocks/GOOG.csv\n",
      "suchitha/55bb31001ebb40eab50c449bb676aa7f.snappy.parquet\n",
      "suchitha/GOOG.csv.csv\n",
      "suchitha/uploads/sales.csv\n",
      "tatwan/51addc9167684aa281c96fd5ae2d5be2.snappy.parquet\n",
      "tatwan/GOOG.csv\n",
      "tatwan/GOOG_NEW.csv\n",
      "tatwan/buffer.txt\n",
      "taxi_data/\n",
      "taxi_data/8d12668ed190477fa03a29a0a5d50e84_000000_000000.snappy.parquet\n",
      "taxi_data/8d12668ed190477fa03a29a0a5d50e84_000001_000000.snappy.parquet\n",
      "taxi_data/8d12668ed190477fa03a29a0a5d50e84_000002_000000.snappy.parquet\n",
      "taxi_data/8d12668ed190477fa03a29a0a5d50e84_000003_000000.snappy.parquet\n",
      "taxi_data/yellow_tripdata_2024-01.parquet\n",
      "taxi_data/yellow_tripdata_2024-02.parquet\n",
      "taxi_data/yellow_tripdata_2024-03.parquet\n",
      "taxi_data/yellow_tripdata_2024-04.parquet\n",
      "tyler/3a63de0a979f4b22956d913074a48c24.snappy.parquet\n",
      "tyler/tyler_another_file.txt\n",
      "tyler/tyler_file.csv\n",
      "tyler/uploads/goog_stock_file.csv\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'techcatalyst-raw'\n",
    "objects = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "for obj in objects.get('Contents', []):\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86775875",
   "metadata": {},
   "source": [
    "**List only CSV objects in a specific bucket `techcatalyst-raw`**\n",
    "\n",
    "```python\n",
    "# list objects that are CSV in a specific bucket \"techcatalyst-raw\" \n",
    "for obj in objects.get('Contents', []):\n",
    "    # YOUR CODE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ad6acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLAKE/test.csv\n",
      "BLAKE/test2.csv\n",
      "BLAKE/test3.csv\n",
      "BLAKE/test4.csv\n",
      "BLAKE/upload_file_method_GOOG.csv\n",
      "BLAKE_wr/uploads/wr_newfile.csv\n",
      "Ben/gooooog.csv\n",
      "Ben/test.csv\n",
      "EMMA/emna_goog.csv\n",
      "MELISSA/test.csv\n",
      "MELISSA/uploads/GOOG.csv\n",
      "MELISSA/uploads/new_file.csv\n",
      "aamnah/uploads/GOOG_NEW.csv\n",
      "accidents/accidents_2017_to_2023_english.csv\n",
      "alexia/upload_GOOG.csv\n",
      "fabiola/test.csv\n",
      "fabiola/uploads/wr_GOOG.csv\n",
      "jaden/test.csv\n",
      "jaden/uploads/new_file.csv\n",
      "miraj/DOWNLOADEDGOOGLEDATA.csv\n",
      "shaswat/test.csv\n",
      "shaswat/uploads/new_file.csv\n",
      "stage/yellow_tripdata.csv\n",
      "stocks/GOOG.csv\n",
      "suchitha/GOOG.csv.csv\n",
      "suchitha/uploads/sales.csv\n",
      "tatwan/GOOG.csv\n",
      "tatwan/GOOG_NEW.csv\n",
      "tyler/tyler_file.csv\n",
      "tyler/uploads/goog_stock_file.csv\n"
     ]
    }
   ],
   "source": [
    "# List only CSV objects in the techcatalyst-raw bucket\n",
    "for obj in objects.get('Contents', []):\n",
    "    if obj['Key'].endswith('.csv'):\n",
    "        print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5b4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(Bucket='techcatalyst-raw',  # from which bucket\n",
    "                        Key='stocks/GOOG.csv',\n",
    "                        Filename='GOOG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b717e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Date,Open,High,Low,Close,Volume\\r\\n1/2/2025 16:00:00,191.49,193.2,188.71,190.63,17545162\\r\\n1/3/2025 16:'\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "io_temp = io.BytesIO()\n",
    "temp = s3_client.download_fileobj(Bucket='techcatalyst-raw', \n",
    "                           \t\t\tKey='stocks/GOOG.csv',\n",
    "                            \t\tFileobj=io_temp)\n",
    "\n",
    "# show buffer content\n",
    "print(io_temp.getvalue()[:100])\n",
    "\n",
    "with open('google_stock_downloaded.csv', 'wb') as f:\n",
    "    f.write(io_temp.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4712d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_memory_file = io.BytesIO(b\"yello\")\n",
    "s3_client.upload_fileobj(Fileobj=in_memory_file,\n",
    "                          Bucket='techcatalyst-raw', \n",
    "                          Key='michael/michael.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4923b177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "michael/e798e42882254cf5a9e99351bd7626d6.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "for obj in objects.get('Contents', []):\n",
    "    if obj['Key'].startswith('michael/'):\n",
    "        print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10fe1ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import awswrangler as wr\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1fbb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "High",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b10d8e36-9b5e-4f4c-8511-4e90bdfd8cc5",
       "rows": [
        [
         "0",
         "1/2/2025 16:00:00",
         "191.49",
         "193.2",
         "188.71",
         "190.63",
         "17545162"
        ],
        [
         "1",
         "1/3/2025 16:00:00",
         "192.73",
         "194.5",
         "191.35",
         "193.13",
         "12874957"
        ],
        [
         "2",
         "1/6/2025 16:00:00",
         "195.15",
         "199.56",
         "195.06",
         "197.96",
         "19483323"
        ],
        [
         "3",
         "1/7/2025 16:00:00",
         "198.27",
         "202.14",
         "195.94",
         "196.71",
         "16966760"
        ],
        [
         "4",
         "1/8/2025 16:00:00",
         "193.95",
         "197.64",
         "193.75",
         "195.39",
         "14335341"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/2025 16:00:00</td>\n",
       "      <td>191.49</td>\n",
       "      <td>193.20</td>\n",
       "      <td>188.71</td>\n",
       "      <td>190.63</td>\n",
       "      <td>17545162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/3/2025 16:00:00</td>\n",
       "      <td>192.73</td>\n",
       "      <td>194.50</td>\n",
       "      <td>191.35</td>\n",
       "      <td>193.13</td>\n",
       "      <td>12874957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/6/2025 16:00:00</td>\n",
       "      <td>195.15</td>\n",
       "      <td>199.56</td>\n",
       "      <td>195.06</td>\n",
       "      <td>197.96</td>\n",
       "      <td>19483323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/7/2025 16:00:00</td>\n",
       "      <td>198.27</td>\n",
       "      <td>202.14</td>\n",
       "      <td>195.94</td>\n",
       "      <td>196.71</td>\n",
       "      <td>16966760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/8/2025 16:00:00</td>\n",
       "      <td>193.95</td>\n",
       "      <td>197.64</td>\n",
       "      <td>193.75</td>\n",
       "      <td>195.39</td>\n",
       "      <td>14335341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date    Open    High     Low   Close    Volume\n",
       "0  1/2/2025 16:00:00  191.49  193.20  188.71  190.63  17545162\n",
       "1  1/3/2025 16:00:00  192.73  194.50  191.35  193.13  12874957\n",
       "2  1/6/2025 16:00:00  195.15  199.56  195.06  197.96  19483323\n",
       "3  1/7/2025 16:00:00  198.27  202.14  195.94  196.71  16966760\n",
       "4  1/8/2025 16:00:00  193.95  197.64  193.75  195.39  14335341"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wr.s3.read_csv('s3://techcatalyst-raw/stocks/GOOG.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4612fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140 entries, 0 to 139\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    140 non-null    object \n",
      " 1   Open    140 non-null    float64\n",
      " 2   High    140 non-null    float64\n",
      " 3   Low     140 non-null    float64\n",
      " 4   Close   140 non-null    float64\n",
      " 5   Volume  140 non-null    int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 6.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e399586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Database       Description\n",
      "0             aamnah_db                  \n",
      "1           aamnah_taxi                  \n",
      "2             alexia_db                  \n",
      "3           alexia_logs                  \n",
      "4           alexia_song                  \n",
      "5      awswrangler_test                  \n",
      "6                ben_db                  \n",
      "7              ben_song                  \n",
      "8              ben_taxi                  \n",
      "9            blake_taxi                  \n",
      "10          blake_wr_db                  \n",
      "11              default  default database\n",
      "12              emma_db                  \n",
      "13            emma_taxi                  \n",
      "14           fabiola_db                  \n",
      "15         fabiola_taxi                  \n",
      "16           jaden_taxi                  \n",
      "17        jadenastle_db                  \n",
      "18           melissa_db                  \n",
      "19         melissa_logs                  \n",
      "20        melissa_songs                  \n",
      "21         melissa_taxi                  \n",
      "22           michael_db                  \n",
      "23             miraj_db                  \n",
      "24           miraj_taxi                  \n",
      "25                my_db                  \n",
      "26           shaswat_db                  \n",
      "27         shaswat_logs                  \n",
      "28         shaswat_song                  \n",
      "29         shaswat_taxi                  \n",
      "30          suchitha_db                  \n",
      "31        suchitha_taxi                  \n",
      "32            tatwan_db                  \n",
      "33  tatwan_inclass_demo                  \n",
      "34          tatwan_taxi                  \n",
      "35             tyler_db                  \n",
      "36           tyler_taxi                  \n"
     ]
    }
   ],
   "source": [
    "databases = wr.catalog.databases()\n",
    "print(databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbc40085",
   "metadata": {},
   "outputs": [
    {
     "ename": "AlreadyExists",
     "evalue": "Database michael_db already exists and <exist_ok> is set to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAlreadyExists\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m name = \u001b[33m\"\u001b[39m\u001b[33mmichael\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m database_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_db\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mwr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/dev/lib/python3.13/site-packages/awswrangler/_config.py:712\u001b[39m, in \u001b[36mapply_configs.<locals>.wrapper\u001b[39m\u001b[34m(*args_raw, **kwargs)\u001b[39m\n\u001b[32m    710\u001b[39m         \u001b[38;5;28;01mdel\u001b[39;00m args[name]\n\u001b[32m    711\u001b[39m         args = {**args, **keywords}\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/dev/lib/python3.13/site-packages/awswrangler/catalog/_create.py:712\u001b[39m, in \u001b[36mcreate_database\u001b[39m\u001b[34m(name, description, catalog_id, exist_ok, database_input_args, boto3_session)\u001b[39m\n\u001b[32m    710\u001b[39m r = client_glue.get_database(**_catalog_id(catalog_id=catalog_id, Name=name))\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok:\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.AlreadyExists(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDatabase \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m already exists and <exist_ok> is set to False.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m args.items():\n\u001b[32m    714\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m v != r[\u001b[33m\"\u001b[39m\u001b[33mDatabase\u001b[39m\u001b[33m\"\u001b[39m].get(k, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mAlreadyExists\u001b[39m: Database michael_db already exists and <exist_ok> is set to False."
     ]
    }
   ],
   "source": [
    "name = \"michael\"\n",
    "database_name = f\"{name}_db\"\n",
    "wr.catalog.create_database(database_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2fc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Database       Description\n",
      "0           alexia_logs                  \n",
      "1           alexia_song                  \n",
      "2      awswrangler_test                  \n",
      "3              ben_song                  \n",
      "4           blake_wr_db                  \n",
      "5               default  default database\n",
      "6               emma_db                  \n",
      "7         jadenastle_db                  \n",
      "8          melissa_logs                  \n",
      "9         melissa_songs                  \n",
      "10           michael_db                  \n",
      "11                my_db                  \n",
      "12         shaswat_logs                  \n",
      "13         shaswat_song                  \n",
      "14            tatwan_db                  \n",
      "15  tatwan_inclass_demo                  \n",
      "16          tatwan_taxi                  \n"
     ]
    }
   ],
   "source": [
    "databases = wr.catalog.databases()\n",
    "print(databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dcc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Database",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Table",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Description",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TableType",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Columns",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Partitions",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "713d4f08-2571-41b7-948f-d99813df560a",
       "rows": [],
       "shape": {
        "columns": 6,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Database</th>\n",
       "      <th>Table</th>\n",
       "      <th>Description</th>\n",
       "      <th>TableType</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Partitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Database, Table, Description, TableType, Columns, Partitions]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.catalog.tables(database=database_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fb342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://techcatalyst-raw/michael/e798e42882254cf5a9e99351bd7626d6.snappy.parquet'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.s3.to_parquet(\n",
    "    df=df, # the DataFrame you just created \n",
    "    path=f\"s3://techcatalyst-raw/{name}/\", # write to the techcatalyst-raw bucket under your folder name (or it would create a new folder if it does not exist)\n",
    "    dataset=True, \n",
    "    database=database_name, # the name of the database you just created in AWS Glue \n",
    "    table='MICHAEL_STOCK', # pick a table name for example YOURNAME_STOCK\n",
    "    mode='overwrite'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17624b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Database",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Table",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TableType",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Columns",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Partitions",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "966fdc59-46f2-4270-b398-5269d1c5f3b4",
       "rows": [
        [
         "0",
         "michael_db",
         "michael_stock",
         "",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Database</th>\n",
       "      <th>Table</th>\n",
       "      <th>Description</th>\n",
       "      <th>TableType</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Partitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>michael_db</td>\n",
       "      <td>michael_stock</td>\n",
       "      <td></td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Database          Table Description       TableType  \\\n",
       "0  michael_db  michael_stock              EXTERNAL_TABLE   \n",
       "\n",
       "                                Columns Partitions  \n",
       "0  date, open, high, low, close, volume             "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.catalog.tables(database=database_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26623b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Database",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Table",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TableType",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Columns",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Partitions",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d58eabf7-d672-4992-aa78-112e522ffcc0",
       "rows": [
        [
         "0",
         "ben_db",
         "ben_stock",
         "This is my stock table.",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ],
        [
         "1",
         "blake_wr_db",
         "blake_stock",
         "This is my stock table.",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ],
        [
         "2",
         "emma_db",
         "emma_stock",
         "",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ],
        [
         "3",
         "fabiola_db",
         "fabiola_stock",
         "",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ],
        [
         "4",
         "jadenastle_db",
         "jaden_stock",
         "This is my stock table.",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ],
        [
         "5",
         "michael_db",
         "michael_stock",
         "",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ],
        [
         "6",
         "shaswat_db",
         "shaswat_stock",
         "",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ],
        [
         "7",
         "suchitha_db",
         "suchitha_stock",
         "",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ],
        [
         "8",
         "tatwan_db",
         "tatwan_stock",
         "This is my stock table.",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ],
        [
         "9",
         "tatwan_inclass_demo",
         "tatwan_goog_stock",
         "",
         "EXTERNAL_TABLE",
         "date, open, high, low, close, volume",
         ""
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Database</th>\n",
       "      <th>Table</th>\n",
       "      <th>Description</th>\n",
       "      <th>TableType</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Partitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ben_db</td>\n",
       "      <td>ben_stock</td>\n",
       "      <td>This is my stock table.</td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blake_wr_db</td>\n",
       "      <td>blake_stock</td>\n",
       "      <td>This is my stock table.</td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emma_db</td>\n",
       "      <td>emma_stock</td>\n",
       "      <td></td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fabiola_db</td>\n",
       "      <td>fabiola_stock</td>\n",
       "      <td></td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jadenastle_db</td>\n",
       "      <td>jaden_stock</td>\n",
       "      <td>This is my stock table.</td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>michael_db</td>\n",
       "      <td>michael_stock</td>\n",
       "      <td></td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shaswat_db</td>\n",
       "      <td>shaswat_stock</td>\n",
       "      <td></td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>suchitha_db</td>\n",
       "      <td>suchitha_stock</td>\n",
       "      <td></td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tatwan_db</td>\n",
       "      <td>tatwan_stock</td>\n",
       "      <td>This is my stock table.</td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tatwan_inclass_demo</td>\n",
       "      <td>tatwan_goog_stock</td>\n",
       "      <td></td>\n",
       "      <td>EXTERNAL_TABLE</td>\n",
       "      <td>date, open, high, low, close, volume</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Database              Table              Description  \\\n",
       "0               ben_db          ben_stock  This is my stock table.   \n",
       "1          blake_wr_db        blake_stock  This is my stock table.   \n",
       "2              emma_db         emma_stock                            \n",
       "3           fabiola_db      fabiola_stock                            \n",
       "4        jadenastle_db        jaden_stock  This is my stock table.   \n",
       "5           michael_db      michael_stock                            \n",
       "6           shaswat_db      shaswat_stock                            \n",
       "7          suchitha_db     suchitha_stock                            \n",
       "8            tatwan_db       tatwan_stock  This is my stock table.   \n",
       "9  tatwan_inclass_demo  tatwan_goog_stock                            \n",
       "\n",
       "        TableType                               Columns Partitions  \n",
       "0  EXTERNAL_TABLE  date, open, high, low, close, volume             \n",
       "1  EXTERNAL_TABLE  date, open, high, low, close, volume             \n",
       "2  EXTERNAL_TABLE  date, open, high, low, close, volume             \n",
       "3  EXTERNAL_TABLE  date, open, high, low, close, volume             \n",
       "4  EXTERNAL_TABLE  date, open, high, low, close, volume             \n",
       "5  EXTERNAL_TABLE  date, open, high, low, close, volume             \n",
       "6  EXTERNAL_TABLE  date, open, high, low, close, volume             \n",
       "7  EXTERNAL_TABLE  date, open, high, low, close, volume             \n",
       "8  EXTERNAL_TABLE  date, open, high, low, close, volume             \n",
       "9  EXTERNAL_TABLE  date, open, high, low, close, volume             "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.catalog.tables(name_contains=\"stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ce7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "c314b5d3-fd69-41c8-aeee-ca03791e2b46",
       "rows": [
        [
         "0",
         "1/2/2025 16:00:00",
         "191.49",
         "193.2",
         "188.71",
         "190.63",
         "17545162"
        ],
        [
         "1",
         "1/3/2025 16:00:00",
         "192.73",
         "194.5",
         "191.35",
         "193.13",
         "12874957"
        ],
        [
         "2",
         "1/6/2025 16:00:00",
         "195.15",
         "199.56",
         "195.06",
         "197.96",
         "19483323"
        ],
        [
         "3",
         "1/7/2025 16:00:00",
         "198.27",
         "202.14",
         "195.94",
         "196.71",
         "16966760"
        ],
        [
         "4",
         "1/8/2025 16:00:00",
         "193.95",
         "197.64",
         "193.75",
         "195.39",
         "14335341"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/2025 16:00:00</td>\n",
       "      <td>191.49</td>\n",
       "      <td>193.20</td>\n",
       "      <td>188.71</td>\n",
       "      <td>190.63</td>\n",
       "      <td>17545162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/3/2025 16:00:00</td>\n",
       "      <td>192.73</td>\n",
       "      <td>194.50</td>\n",
       "      <td>191.35</td>\n",
       "      <td>193.13</td>\n",
       "      <td>12874957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/6/2025 16:00:00</td>\n",
       "      <td>195.15</td>\n",
       "      <td>199.56</td>\n",
       "      <td>195.06</td>\n",
       "      <td>197.96</td>\n",
       "      <td>19483323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/7/2025 16:00:00</td>\n",
       "      <td>198.27</td>\n",
       "      <td>202.14</td>\n",
       "      <td>195.94</td>\n",
       "      <td>196.71</td>\n",
       "      <td>16966760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/8/2025 16:00:00</td>\n",
       "      <td>193.95</td>\n",
       "      <td>197.64</td>\n",
       "      <td>193.75</td>\n",
       "      <td>195.39</td>\n",
       "      <td>14335341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date    open    high     low   close    volume\n",
       "0  1/2/2025 16:00:00  191.49  193.20  188.71  190.63  17545162\n",
       "1  1/3/2025 16:00:00  192.73  194.50  191.35  193.13  12874957\n",
       "2  1/6/2025 16:00:00  195.15  199.56  195.06  197.96  19483323\n",
       "3  1/7/2025 16:00:00  198.27  202.14  195.94  196.71  16966760\n",
       "4  1/8/2025 16:00:00  193.95  197.64  193.75  195.39  14335341"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = wr.s3.read_parquet_table(database='MICHAEL_DB', \n",
    "                              table='MICHAEL_STOCK')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5c4b147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://techcatalyst-raw/michael/49d5f54d6c4e46b8b4e01f07f7861c35.snappy.parquet'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = \"This is my stock table.\"\n",
    "param = {\"source\": \"Google\", \"class\": \"stock\"}\n",
    "comments = {\n",
    "    \"Date\": \"Trading Date\",\n",
    "    \"Open\": \"Opening Price\",\n",
    "    \"Close\": \"Closing Price\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "wr.s3.to_parquet(\n",
    "    df=df,\n",
    "    path=f\"s3://techcatalyst-raw/{name}/\",  # write to the techcatalyst-raw bucket under your folder name\n",
    "    dataset=True,\n",
    "    database=database_name,\n",
    "    table='MICHAEL_STOCK',\n",
    "    mode='overwrite',\n",
    "    glue_table_settings=wr.typing.GlueTableSettings(description=desc,  # here we are passing some metadata\n",
    "                                                    parameters=param, \n",
    "                                                    columns_comments=comments),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efa420a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Column Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Partition",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Comment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0522b0d8-5e01-4660-9599-8c20190bc965",
       "rows": [
        [
         "0",
         "date",
         "string",
         "False",
         "Trading Date"
        ],
        [
         "1",
         "open",
         "double",
         "False",
         "Opening Price"
        ],
        [
         "2",
         "high",
         "double",
         "False",
         ""
        ],
        [
         "3",
         "low",
         "double",
         "False",
         ""
        ],
        [
         "4",
         "close",
         "double",
         "False",
         "Closing Price"
        ],
        [
         "5",
         "volume",
         "bigint",
         "False",
         ""
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>string</td>\n",
       "      <td>False</td>\n",
       "      <td>Trading Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>open</td>\n",
       "      <td>double</td>\n",
       "      <td>False</td>\n",
       "      <td>Opening Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>double</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>double</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>close</td>\n",
       "      <td>double</td>\n",
       "      <td>False</td>\n",
       "      <td>Closing Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>volume</td>\n",
       "      <td>bigint</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column Name    Type  Partition        Comment\n",
       "0        date  string      False   Trading Date\n",
       "1        open  double      False  Opening Price\n",
       "2        high  double      False               \n",
       "3         low  double      False               \n",
       "4       close  double      False  Closing Price\n",
       "5      volume  bigint      False               "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name = 'MICHAEL_STOCK'\n",
    "wr.catalog.table(database=database_name, table=table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77a6f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.s3.list_objects('s3://techcatalyst-raw/stage/')\n",
    "\n",
    "wr.s3.download(path='s3://techcatalyst-raw/stocks/GOOG.csv', \n",
    "               local_file='./new_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba56ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = 'michael'\n",
    "file_name = 'new_file_stocks.csv'\n",
    "wr.s3.upload(local_file='new_file.csv',path= f's3://techcatalyst-raw/{your_name}/uploads/{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abaaf3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://techcatalyst-raw/michael/uploads/new_file_stocks.csv']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.s3.list_objects(f's3://techcatalyst-raw/michael/uploads/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5d535da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A name for the new Glue Database it should be YOURNAME_TAXI\n",
    "db_name = 'michael_taxi'\n",
    "\n",
    "# A name for the table it should be YOURNAME_TRIPDATA\n",
    "table_name = 'michael_tripdata'\n",
    "\n",
    "# the path_direcoty to should point to the bucket (main directory)\n",
    "s3_path_directory = 's3://techcatalyst-raw/taxi_data/'\n",
    "\n",
    "# The path_file should be the full path to the actual file\n",
    "s3_path_file = 's3://techcatalyst-raw/taxi_data/yellow_tripdata_2024-03.parquet'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eeb4f07a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AlreadyExists",
     "evalue": "Database michael_taxi already exists and <exist_ok> is set to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAlreadyExists\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# wr.catalog.delete_table_if_exists(database=db_name, table=table_name)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mwr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m columns_types, partitions_types = wr.s3.read_parquet_metadata(path=s3_path_file)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSuccessfully read schema from Parquet file.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/dev/lib/python3.13/site-packages/awswrangler/_config.py:712\u001b[39m, in \u001b[36mapply_configs.<locals>.wrapper\u001b[39m\u001b[34m(*args_raw, **kwargs)\u001b[39m\n\u001b[32m    710\u001b[39m         \u001b[38;5;28;01mdel\u001b[39;00m args[name]\n\u001b[32m    711\u001b[39m         args = {**args, **keywords}\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/dev/lib/python3.13/site-packages/awswrangler/catalog/_create.py:712\u001b[39m, in \u001b[36mcreate_database\u001b[39m\u001b[34m(name, description, catalog_id, exist_ok, database_input_args, boto3_session)\u001b[39m\n\u001b[32m    710\u001b[39m r = client_glue.get_database(**_catalog_id(catalog_id=catalog_id, Name=name))\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok:\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.AlreadyExists(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDatabase \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m already exists and <exist_ok> is set to False.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m args.items():\n\u001b[32m    714\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m v != r[\u001b[33m\"\u001b[39m\u001b[33mDatabase\u001b[39m\u001b[33m\"\u001b[39m].get(k, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mAlreadyExists\u001b[39m: Database michael_taxi already exists and <exist_ok> is set to False."
     ]
    }
   ],
   "source": [
    "# wr.catalog.delete_table_if_exists(database=db_name, table=table_name)\n",
    "\n",
    "wr.catalog.create_database(db_name)\n",
    "\n",
    "columns_types, partitions_types = wr.s3.read_parquet_metadata(path=s3_path_file)\n",
    "print(\"Successfully read schema from Parquet file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "919b810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'michael_tripdata' created successfully in database 'michael_taxi'.\n"
     ]
    }
   ],
   "source": [
    "wr.catalog.create_parquet_table(\n",
    "    database=db_name, # pass the database name\n",
    "    table=table_name, # pass the table name\n",
    "    path=s3_path_directory, # use the directoy here \n",
    "    columns_types=columns_types,  # Pass the schema here\n",
    "    partitions_types=partitions_types\n",
    ")\n",
    "print(f\"Table '{table_name}' created successfully in database '{db_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1155d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Results:\n",
      "   vendorid tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2024-04-03 17:49:47   2024-04-03 18:39:29              NaN   \n",
      "1         2  2024-04-03 17:58:05   2024-04-03 18:04:41              NaN   \n",
      "2         2  2024-04-03 17:27:15   2024-04-03 17:58:46              NaN   \n",
      "3         2  2024-04-03 17:01:56   2024-04-03 17:31:43              NaN   \n",
      "4         2  2024-04-03 17:42:09   2024-04-03 17:42:57              NaN   \n",
      "\n",
      "   trip_distance  ratecodeid store_and_fwd_flag  pulocationid  dolocationid  \\\n",
      "0           3.77         NaN               <NA>           236           234   \n",
      "1           0.70         NaN               <NA>           233           233   \n",
      "2           4.63         NaN               <NA>           237           246   \n",
      "3           3.32         NaN               <NA>            87           186   \n",
      "4           0.00         NaN               <NA>           246           246   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             0        35.71    0.0      0.5        0.00           0.0   \n",
      "1             0        14.22    0.0      0.5        2.73           0.0   \n",
      "2             0        31.38    0.0      0.5        0.00           0.0   \n",
      "3             0        35.56    0.0      0.5        0.00           0.0   \n",
      "4             0        14.22    0.0      0.5        3.64           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
      "0                    1.0         39.71                   NaN          NaN  \n",
      "1                    1.0         20.95                   NaN          NaN  \n",
      "2                    1.0         35.38                   NaN          NaN  \n",
      "3                    1.0         39.56                   NaN          NaN  \n",
      "4                    1.0         21.86                   NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "query = f\"SELECT * FROM {table_name} LIMIT 5\"\n",
    "\n",
    "df = wr.athena.read_sql_query(query, database=db_name)\n",
    "\n",
    "print(\"\\nQuery Results:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9993d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete AWS Lambda Function Code for CSV to Parquet Conversion\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "from urllib.parse import unquote_plus\n",
    "import json\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # Get the source bucket and object name from the Lambda event\n",
    "    for record in event['Records']:\n",
    "        source_bucket = record['s3']['bucket']['name']\n",
    "        source_key = unquote_plus(record['s3']['object']['key'])\n",
    "    \n",
    "    print(f'Bucket: {source_bucket}')\n",
    "    print(f'Key: {source_key}')\n",
    "    \n",
    "    input_path = f\"s3://{source_bucket}/{source_key}\"\n",
    "    print(f'Input Path: {input_path}')\n",
    "    \n",
    "    # Define the destination bucket and key\n",
    "    destination_bucket = \"techcatalyst-public\"  # Target bucket name as a string\n",
    "    \n",
    "    # Derive the output key (keep same folder structure, replace file extension with .parquet)\n",
    "    if source_key.lower().endswith('.csv'):\n",
    "        output_key = source_key[:-4] + \".parquet\"\n",
    "    else:\n",
    "        output_key = source_key + \".parquet\"\n",
    "        \n",
    "    output_path = f\"s3://{destination_bucket}/{output_key}\"\n",
    "    print(f'Output Path: {output_path}')\n",
    "    \n",
    "    # Read the CSV file from S3\n",
    "    try:\n",
    "        input_df = wr.s3.read_csv([input_path])\n",
    "    except Exception as e:\n",
    "        print(\"error on read\")\n",
    "        print(e)\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps('Error reading source CSV file')\n",
    "        }\n",
    "    \n",
    "    # Write the DataFrame to Parquet format in the destination S3 bucket\n",
    "    result = wr.s3.to_parquet(\n",
    "        df=input_df,                    # The DataFrame to write\n",
    "        path=output_path,               # S3 path for the output file\n",
    "        dataset=False,                  # Single file, not partitioned dataset\n",
    "        compression='snappy'            # Compression for better performance\n",
    "    )\n",
    "    \n",
    "    print(\"RESULT: \")\n",
    "    print(result)\n",
    "    \n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('CSV file converted to Parquet and moved successfully!')\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
